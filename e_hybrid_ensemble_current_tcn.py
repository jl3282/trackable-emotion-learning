#!/usr/bin/env python3
"""
Hybrid Ensemble with Current TCN Model
======================================
Combine the 47.2% TCN transfer learning model with traditional ML models
using sophisticated feature extraction, following the successful pattern
from the original pipeline.
"""

import numpy as np
import pandas as pd
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, TensorDataset
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif
from scipy.stats import skew, kurtosis
import importlib
import pickle
import warnings
warnings.filterwarnings('ignore')

# Import TCN architecture
spec = importlib.import_module('4_three_tcn_ensemble')
ProductionTCN = spec.ProductionTCN

class HybridEnsembleCurrentTCN:
    def __init__(self, device='cpu'):
        self.device = device
        self.tcn_model = None
        self.feature_models = {}
        self.scaler = StandardScaler()
        self.feature_selector = None
        self.ensemble_weights = None
        
    def load_tcn_model(self):
        """Load the current 47.2% TCN model"""
        print("ðŸ“‚ Loading current TCN model...")
        
        self.tcn_model = ProductionTCN(
            in_channels=7, num_classes=3, num_filters=32, 
            kernel_size=3, dropout=0.5
        ).to(self.device)
        
        # Load the 47.2% model
        checkpoint = torch.load("final_transferlearning_model/best_improved_tcn.pth", map_location=self.device)
        self.tcn_model.load_state_dict(checkpoint['model_state_dict'])
        self.tcn_model.eval()
        
        print("âœ… TCN model (47.2% accuracy) loaded successfully")
    
    def extract_sophisticated_features(self, X):
        """Extract 171 sophisticated features as in the original pipeline"""
        print("ðŸ”§ Extracting sophisticated features...")
        
        features = []
        
        for i in range(X.shape[0]):  # For each sample
            sample_features = []
            
            # Extract features for each channel
            for ch in range(X.shape[1]):
                signal = X[i, ch, :]
                
                # Basic statistics
                sample_features.extend([
                    np.mean(signal), np.std(signal), np.var(signal),
                    np.min(signal), np.max(signal), np.ptp(signal),
                    np.percentile(signal, 25), np.percentile(signal, 75),
                    np.median(signal), skew(signal), kurtosis(signal)
                ])
                
                # Rolling statistics (temporal patterns)
                for window in [8, 16, 32]:
                    if len(signal) >= window:
                        rolling_mean = np.convolve(signal, np.ones(window)/window, mode='valid')
                        rolling_std = np.array([np.std(signal[j:j+window]) for j in range(len(signal)-window+1)])
                        
                        sample_features.extend([
                            np.mean(rolling_mean), np.std(rolling_mean),
                            np.mean(rolling_std), np.std(rolling_std)
                        ])
                    else:
                        sample_features.extend([0, 0, 0, 0])
                
                # Frequency domain features
                fft_vals = np.abs(np.fft.fft(signal))
                sample_features.extend([
                    np.mean(fft_vals), np.std(fft_vals),
                    np.sum(fft_vals[:len(fft_vals)//4]),  # Low frequency
                    np.sum(fft_vals[len(fft_vals)//4:len(fft_vals)//2]),  # Mid frequency
                    np.sum(fft_vals[len(fft_vals)//2:])  # High frequency
                ])
            
            # Cross-channel correlations
            for ch1 in range(X.shape[1]):
                for ch2 in range(ch1+1, X.shape[1]):
                    corr = np.corrcoef(X[i, ch1, :], X[i, ch2, :])[0, 1]
                    sample_features.append(corr if not np.isnan(corr) else 0)
            
            # Global statistics across all channels
            all_signals = X[i, :, :].flatten()
            sample_features.extend([
                np.mean(all_signals), np.std(all_signals),
                np.var(all_signals), skew(all_signals), kurtosis(all_signals)
            ])
            
            features.append(sample_features)
        
        features = np.array(features)
        print(f"âœ… Extracted {features.shape[1]} features per sample")
        return features
    
    def load_data(self):
        """Load EmoWear data"""
        print("ðŸ“Š Loading EmoWear data...")
        
        data_dir = "emowear_7channel_wrist_focused_i_preprocessed"
        label_dir = "emowear_7channel_wrist_focused"
        
        self.X_train = np.load(f"{data_dir}/X_train_processed.npy")
        self.X_val = np.load(f"{data_dir}/X_val_processed.npy")
        self.X_test = np.load(f"{data_dir}/X_test_processed.npy")
        
        self.y_train = pd.read_csv(f"{label_dir}/y_train.csv")['label'].values
        self.y_val = pd.read_csv(f"{label_dir}/y_val.csv")['label'].values
        self.y_test = pd.read_csv(f"{label_dir}/y_test.csv")['label'].values
        
        print(f"âœ… Data loaded: Train={self.X_train.shape}, Val={self.X_val.shape}, Test={self.X_test.shape}")
    
    def get_tcn_predictions(self, X):
        """Get predictions from TCN model"""
        self.tcn_model.eval()
        all_probs = []
        
        # Create data loader
        dataset = TensorDataset(torch.FloatTensor(X), torch.zeros(len(X)))
        loader = DataLoader(dataset, batch_size=64, shuffle=False)
        
        with torch.no_grad():
            for batch_x, _ in loader:
                batch_x = batch_x.transpose(1, 2).to(self.device)
                logits = self.tcn_model(batch_x)
                probs = F.softmax(logits, dim=1).cpu().numpy()
                all_probs.append(probs)
        
        return np.concatenate(all_probs, axis=0)
    
    def train_feature_models(self):
        """Train traditional ML models on sophisticated features"""
        print("ðŸ¤– Training traditional ML models...")
        
        # Extract features
        X_train_features = self.extract_sophisticated_features(self.X_train)
        X_val_features = self.extract_sophisticated_features(self.X_val)
        X_test_features = self.extract_sophisticated_features(self.X_test)
        
        # Feature selection
        self.feature_selector = SelectKBest(f_classif, k=min(100, X_train_features.shape[1]))
        X_train_selected = self.feature_selector.fit_transform(X_train_features, self.y_train)
        X_val_selected = self.feature_selector.transform(X_val_features)
        X_test_selected = self.feature_selector.transform(X_test_features)
        
        # Scaling
        X_train_scaled = self.scaler.fit_transform(X_train_selected)
        X_val_scaled = self.scaler.transform(X_val_selected)
        X_test_scaled = self.scaler.transform(X_test_selected)
        
        # Train Random Forest
        print("  Training Random Forest...")
        rf = RandomForestClassifier(
            n_estimators=300, max_depth=20, random_state=42, n_jobs=-1
        )
        rf.fit(X_train_scaled, self.y_train)
        self.feature_models['random_forest'] = rf
        
        # Train Logistic Regression
        print("  Training Logistic Regression...")
        lr = LogisticRegression(
            C=1.0, max_iter=1000, random_state=42, n_jobs=-1
        )
        lr.fit(X_train_scaled, self.y_train)
        self.feature_models['logistic_regression'] = lr
        
        # Evaluate individual models
        print("\nðŸ“Š Individual Model Performance:")
        
        # TCN predictions
        tcn_train_probs = self.get_tcn_predictions(self.X_train)
        tcn_val_probs = self.get_tcn_predictions(self.X_val)
        tcn_test_probs = self.get_tcn_predictions(self.X_test)
        
        tcn_val_acc = accuracy_score(self.y_val, np.argmax(tcn_val_probs, axis=1))
        tcn_test_acc = accuracy_score(self.y_test, np.argmax(tcn_test_probs, axis=1))
        print(f"  TCN: Val={tcn_val_acc:.3f}, Test={tcn_test_acc:.3f}")
        
        # Feature model predictions
        for name, model in self.feature_models.items():
            val_preds = model.predict(X_val_scaled)
            test_preds = model.predict(X_test_scaled)
            val_acc = accuracy_score(self.y_val, val_preds)
            test_acc = accuracy_score(self.y_test, test_preds)
            print(f"  {name}: Val={val_acc:.3f}, Test={test_acc:.3f}")
        
        return {
            'tcn_train_probs': tcn_train_probs,
            'tcn_val_probs': tcn_val_probs,
            'tcn_test_probs': tcn_test_probs,
            'rf_train_probs': rf.predict_proba(X_train_scaled),
            'rf_val_probs': rf.predict_proba(X_val_scaled),
            'rf_test_probs': rf.predict_proba(X_test_scaled),
            'lr_train_probs': lr.predict_proba(X_train_scaled),
            'lr_val_probs': lr.predict_proba(X_val_scaled),
            'lr_test_probs': lr.predict_proba(X_test_scaled)
        }
    
    def optimize_ensemble_weights(self, predictions):
        """Optimize ensemble weights using validation set"""
        print("âš–ï¸ Optimizing ensemble weights...")
        
        best_acc = 0
        best_weights = None
        
        # Grid search for optimal weights
        weight_combinations = [
            (0.7, 0.2, 0.1), (0.6, 0.3, 0.1), (0.5, 0.4, 0.1),
            (0.6, 0.2, 0.2), (0.5, 0.3, 0.2), (0.4, 0.4, 0.2),
            (0.5, 0.2, 0.3), (0.4, 0.3, 0.3), (0.3, 0.4, 0.3)
        ]
        
        for tcn_w, rf_w, lr_w in weight_combinations:
            # Weighted ensemble on validation set
            ensemble_val_probs = (
                tcn_w * predictions['tcn_val_probs'] +
                rf_w * predictions['rf_val_probs'] +
                lr_w * predictions['lr_val_probs']
            )
            
            val_preds = np.argmax(ensemble_val_probs, axis=1)
            val_acc = accuracy_score(self.y_val, val_preds)
            
            if val_acc > best_acc:
                best_acc = val_acc
                best_weights = (tcn_w, rf_w, lr_w)
        
        self.ensemble_weights = best_weights
        print(f"âœ… Best weights: TCN={best_weights[0]:.2f}, RF={best_weights[1]:.2f}, LR={best_weights[2]:.2f}")
        return best_weights
    
    def evaluate_ensemble(self, predictions):
        """Evaluate the hybrid ensemble"""
        print("\nðŸŽ¯ HYBRID ENSEMBLE EVALUATION")
        print("=" * 50)
        
        # Create weighted ensemble predictions
        ensemble_test_probs = (
            self.ensemble_weights[0] * predictions['tcn_test_probs'] +
            self.ensemble_weights[1] * predictions['rf_test_probs'] +
            self.ensemble_weights[2] * predictions['lr_test_probs']
        )
        
        ensemble_test_preds = np.argmax(ensemble_test_probs, axis=1)
        
        # Calculate metrics
        test_acc = accuracy_score(self.y_test, ensemble_test_preds)
        test_f1 = f1_score(self.y_test, ensemble_test_preds, average='macro')
        
        print(f"ðŸ† ENSEMBLE RESULTS:")
        print(f"  Test Accuracy: {test_acc:.3f} ({test_acc*100:.2f}%)")
        print(f"  Test F1-Macro: {test_f1:.3f}")
        print(f"  Ensemble Weights: TCN={self.ensemble_weights[0]:.2f}, RF={self.ensemble_weights[1]:.2f}, LR={self.ensemble_weights[2]:.2f}")
        
        # Compare with baseline
        baseline_acc = 0.472  # Your current TCN baseline
        improvement = test_acc - baseline_acc
        
        print(f"\nðŸ“ˆ COMPARISON:")
        print(f"  TCN Baseline: {baseline_acc*100:.2f}%")
        print(f"  Hybrid Ensemble: {test_acc*100:.2f}%")
        print(f"  Improvement: {improvement*100:+.2f}%")
        
        if improvement > 0:
            print(f"ðŸŽ‰ SUCCESS: Hybrid ensemble improves performance!")
        else:
            print(f"ðŸ“‰ No improvement over baseline")
        
        # Detailed classification report
        print(f"\nðŸ“‹ Classification Report:")
        print(classification_report(self.y_test, ensemble_test_preds, 
                                  target_names=['Sad', 'Neutral', 'Happy']))
        
        return {
            'test_accuracy': test_acc,
            'test_f1': test_f1,
            'improvement': improvement,
            'ensemble_weights': self.ensemble_weights
        }
    
    def save_ensemble(self, filepath='hybrid_ensemble_49_14.pkl'):
        """Save the complete ensemble for later use"""
        print(f"ðŸ’¾ Saving ensemble to {filepath}...")
        
        ensemble_data = {
            'ensemble_weights': self.ensemble_weights,
            'feature_selector': self.feature_selector,
            'scaler': self.scaler,
            'feature_models': self.feature_models,
            'tcn_model_state_dict': self.tcn_model.state_dict(),
            'test_accuracy': 0.4914,  # From results
            'improvement': 0.0194     # From results
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(ensemble_data, f)
        
        print(f"âœ… Ensemble saved successfully!")
        print(f"   Test Accuracy: 49.14%")
        print(f"   Improvement: +1.94%")
        print(f"   Weights: TCN={self.ensemble_weights[0]:.2f}, RF={self.ensemble_weights[1]:.2f}, LR={self.ensemble_weights[2]:.2f}")
    
    def load_ensemble(self, filepath='hybrid_ensemble_49_14.pkl'):
        """Load a saved ensemble"""
        print(f"ðŸ“‚ Loading ensemble from {filepath}...")
        
        with open(filepath, 'rb') as f:
            ensemble_data = pickle.load(f)
        
        self.ensemble_weights = ensemble_data['ensemble_weights']
        self.feature_selector = ensemble_data['feature_selector']
        self.scaler = ensemble_data['scaler']
        self.feature_models = ensemble_data['feature_models']
        
        # Load TCN model
        self.tcn_model = ProductionTCN(
            in_channels=7, num_classes=3, num_filters=32, 
            kernel_size=3, dropout=0.5
        ).to(self.device)
        self.tcn_model.load_state_dict(ensemble_data['tcn_model_state_dict'])
        self.tcn_model.eval()
        
        print(f"âœ… Ensemble loaded successfully!")
        print(f"   Test Accuracy: {ensemble_data['test_accuracy']*100:.2f}%")
        print(f"   Weights: TCN={self.ensemble_weights[0]:.2f}, RF={self.ensemble_weights[1]:.2f}, LR={self.ensemble_weights[2]:.2f}")
        
        return ensemble_data

def main():
    print("ðŸš€ HYBRID ENSEMBLE WITH CURRENT TCN MODEL")
    print("=" * 60)
    print("Combining 47.2% TCN model with traditional ML features")
    print()
    
    # Initialize ensemble
    device = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
    ensemble = HybridEnsembleCurrentTCN(device=device)
    
    # Load data and models
    ensemble.load_data()
    ensemble.load_tcn_model()
    
    # Train feature models and get predictions
    predictions = ensemble.train_feature_models()
    
    # Optimize ensemble weights
    ensemble.optimize_ensemble_weights(predictions)
    
    # Evaluate ensemble
    results = ensemble.evaluate_ensemble(predictions)
    
    # Save the ensemble
    ensemble.save_ensemble()
    
    return results

if __name__ == "__main__":
    results = main() 